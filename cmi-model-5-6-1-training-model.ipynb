{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":102335,"databundleVersionId":12518947,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":12923148,"sourceType":"datasetVersion","datasetId":8177404},{"sourceId":12923155,"sourceType":"datasetVersion","datasetId":8177410},{"sourceId":240649816,"sourceType":"kernelVersion"},{"sourceId":251413288,"sourceType":"kernelVersion"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-01T10:52:39.424081Z","iopub.execute_input":"2025-09-01T10:52:39.424340Z","iopub.status.idle":"2025-09-01T10:52:39.446506Z","shell.execute_reply.started":"2025-09-01T10:52:39.424320Z","shell.execute_reply":"2025-09-01T10:52:39.445963Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/k/wasupandceacar/wasupandceacar/cmi-metric/__results__.html\n/kaggle/input/k/wasupandceacar/wasupandceacar/cmi-metric/__package_validation_results__.txt\n/kaggle/input/k/wasupandceacar/wasupandceacar/cmi-metric/__notebook__.ipynb\n/kaggle/input/k/wasupandceacar/wasupandceacar/cmi-metric/__output__.json\n/kaggle/input/k/wasupandceacar/wasupandceacar/cmi-metric/custom.css\n/kaggle/input/k/wasupandceacar/wasupandceacar/cmi-metric/package/kagglehub_requirements.yaml\n/kaggle/input/k/wasupandceacar/wasupandceacar/cmi-metric/package/core.py\n/kaggle/input/k/wasupandceacar/wasupandceacar/cmi-metric/package/__init__.py\n/kaggle/input/cmi-model-3-label-encoder/label_encoder.pkl\n/kaggle/input/cmi-model-3-utilities/train_universe.csv\n/kaggle/input/cmi-model-3-utilities/best_fold3.pt\n/kaggle/input/cmi-model-3-utilities/best_fold2.pt\n/kaggle/input/cmi-model-3-utilities/best_fold0.pt\n/kaggle/input/cmi-model-3-utilities/best_fold1.pt\n/kaggle/input/cmi-model-3-utilities/best_fold4.pt\n/kaggle/input/wasupandceacar/deterministic/__results__.html\n/kaggle/input/wasupandceacar/deterministic/__package_validation_results__.txt\n/kaggle/input/wasupandceacar/deterministic/__notebook__.ipynb\n/kaggle/input/wasupandceacar/deterministic/__output__.json\n/kaggle/input/wasupandceacar/deterministic/custom.css\n/kaggle/input/wasupandceacar/deterministic/package/kagglehub_requirements.yaml\n/kaggle/input/wasupandceacar/deterministic/package/core.py\n/kaggle/input/wasupandceacar/deterministic/package/__init__.py\n/kaggle/input/cmi-detect-behavior-with-sensor-data/train_demographics.csv\n/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv\n/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv\n/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv\n/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/cmi_inference_server.py\n/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/cmi_gateway.py\n/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/__init__.py\n/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/templates.py\n/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/base_gateway.py\n/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/relay.py\n/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/kaggle_evaluation.proto\n/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/__init__.py\n/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/generated/__init__.py\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# **Libraries**","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport kagglehub\nfrom pathlib import Path\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom scipy.spatial.transform import Rotation as R\nfrom collections import defaultdict\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom tqdm.notebook import tqdm\nfrom torch.amp import autocast\nimport pandas as pd\nimport polars as pl\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom transformers import BertConfig, BertModel\nimport time\nimport joblib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T10:52:39.447555Z","iopub.execute_input":"2025-09-01T10:52:39.447780Z","iopub.status.idle":"2025-09-01T10:53:03.378975Z","shell.execute_reply.started":"2025-09-01T10:52:39.447763Z","shell.execute_reply":"2025-09-01T10:53:03.378364Z"}},"outputs":[{"name":"stderr","text":"2025-09-01 10:52:52.819625: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756723972.991027      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756723973.039141      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# **Preprocessing Functions**","metadata":{}},{"cell_type":"code","source":"# Removing the gravity\ndef remove_gravity_from_acc(acc_data, rot_data):\n    if isinstance(acc_data, pd.DataFrame):\n        acc_values = acc_data[['acc_x', 'acc_y', 'acc_z']].values\n    else:\n        acc_values = acc_data\n    if isinstance(rot_data, pd.DataFrame):\n        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n    else:\n        quat_values = rot_data\n    num_samples = acc_values.shape[0]\n    linear_accel = np.zeros_like(acc_values)\n    gravity_world = np.array([0, 0, 9.81])\n    for i in range(num_samples):\n        if np.all(np.isnan(quat_values[i])) or np.all(np.isclose(quat_values[i], 0)):\n            linear_accel[i, :] = acc_values[i, :] \n            continue\n        try:\n            rotation = R.from_quat(quat_values[i])\n            gravity_sensor_frame = rotation.apply(gravity_world, inverse=True)\n            linear_accel[i, :] = acc_values[i, :] - gravity_sensor_frame\n        except ValueError:\n             linear_accel[i, :] = acc_values[i, :]\n    return linear_accel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T10:53:03.379649Z","iopub.execute_input":"2025-09-01T10:53:03.380111Z","iopub.status.idle":"2025-09-01T10:53:03.386120Z","shell.execute_reply.started":"2025-09-01T10:53:03.380091Z","shell.execute_reply":"2025-09-01T10:53:03.385433Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Calclate angular velocity\ndef calculate_angular_velocity_from_quat(rot_data, time_delta=1/200): # Assuming 200Hz sampling rate\n    if isinstance(rot_data, pd.DataFrame):\n        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n    else:\n        quat_values = rot_data\n    num_samples = quat_values.shape[0]\n    angular_vel = np.zeros((num_samples, 3))\n    for i in range(num_samples - 1):\n        q_t = quat_values[i]\n        q_t_plus_dt = quat_values[i+1]\n        if np.all(np.isnan(q_t)) or np.all(np.isclose(q_t, 0)) or \\\n           np.all(np.isnan(q_t_plus_dt)) or np.all(np.isclose(q_t_plus_dt, 0)):\n            continue\n        try:\n            rot_t = R.from_quat(q_t)\n            rot_t_plus_dt = R.from_quat(q_t_plus_dt)\n            delta_rot = rot_t.inv() * rot_t_plus_dt\n            angular_vel[i, :] = delta_rot.as_rotvec() / time_delta\n        except ValueError:\n            pass\n    return angular_vel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T10:53:03.386977Z","iopub.execute_input":"2025-09-01T10:53:03.387271Z","iopub.status.idle":"2025-09-01T10:53:03.415413Z","shell.execute_reply.started":"2025-09-01T10:53:03.387239Z","shell.execute_reply":"2025-09-01T10:53:03.414773Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Calculate Angular Distance\ndef calculate_angular_distance(rot_data):\n    if isinstance(rot_data, pd.DataFrame):\n        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n    else:\n        quat_values = rot_data\n    num_samples = quat_values.shape[0]\n    angular_dist = np.zeros(num_samples)\n    for i in range(num_samples - 1):\n        q1 = quat_values[i]\n        q2 = quat_values[i+1]\n        if np.all(np.isnan(q1)) or np.all(np.isclose(q1, 0)) or \\\n           np.all(np.isnan(q2)) or np.all(np.isclose(q2, 0)):\n            angular_dist[i] = 0\n            continue\n        try:\n            r1 = R.from_quat(q1)\n            r2 = R.from_quat(q2)\n            relative_rotation = r1.inv() * r2\n            angle = np.linalg.norm(relative_rotation.as_rotvec())\n            angular_dist[i] = angle\n        except ValueError:\n            angular_dist[i] = 0 \n            pass\n    return angular_dist","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T10:53:03.417237Z","iopub.execute_input":"2025-09-01T10:53:03.417508Z","iopub.status.idle":"2025-09-01T10:53:03.429649Z","shell.execute_reply.started":"2025-09-01T10:53:03.417491Z","shell.execute_reply":"2025-09-01T10:53:03.429091Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# **Dataset Classes and Functions**","metadata":{}},{"cell_type":"markdown","source":"This `CMIFeDataset` class is a **PyTorch Dataset** that:\n\n1. **Loads raw CSV data** (with IMU, thermal, and ToF sensor readings) and **config settings**.\n2. **Initializes feature names** (engineered features for IMU, raw & aggregated stats for ToF, etc.).\n3. **Generates or loads engineered features** if they’re not already precomputed:\n\n   * IMU features: magnitudes, jerks, rotation angles, angular velocities/distances, gravity removal, etc.\n   * ToF features: per-sensor statistics (mean, std, min, max) and optionally region-based aggregation.\n4. **Encodes labels** (`gesture`) into integers and one-hot vectors.\n5. **Handles missing data**:\n\n   * Fills with forward/backward fill if configured.\n   * Replaces remaining NaNs with a synthetic “nan value” that is later scaled consistently.\n6. **Scales features** (either all at once or per-sensor type) using `StandardScaler`.\n7. **Pads sequences** to a fixed length (`pad_len`, chosen as the 95th percentile of sequence lengths).\n8. **Stores ready-to-train tensors** for IMU, thermal, and ToF data plus labels & class weights.\n9. Provides:\n\n   * **`__getitem__`** for PyTorch DataLoader compatibility.\n   * **`inference_process`** for preparing new sequences in the exact same way as training data.\n   * Utilities for getting scaled NaN tensors.\n\nBasically — it’s a **complete dataset preparation pipeline** for a multimodal time-series classification task, handling:\n\n* 1) Feature engineering\n* 2) Missing data \n* 3) Normalization\n* 4) Padding\n* 5) Label encoding\n* 6) Train/inference consistency ","metadata":{}},{"cell_type":"code","source":"data_path = '/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T10:53:03.430389Z","iopub.execute_input":"2025-09-01T10:53:03.430628Z","iopub.status.idle":"2025-09-01T10:53:03.441182Z","shell.execute_reply.started":"2025-09-01T10:53:03.430602Z","shell.execute_reply":"2025-09-01T10:53:03.440477Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"**Steps to Convert Raw Dataset → Required Format**","metadata":{}},{"cell_type":"code","source":"# import warnings\n# from tqdm import tqdm\n\n# -------------------------\n# Helper functions (user-provided, slightly adapted)\n# -------------------------\ndef remove_gravity_from_acc(acc_data, rot_data):\n    \"\"\"\n    acc_data: DataFrame or ndarray with columns ['acc_x','acc_y','acc_z']\n    rot_data: DataFrame or ndarray with columns ['rot_x','rot_y','rot_z','rot_w']\n    Returns ndarray (N,3) linear acceleration (gravity removed) in sensor frame.\n    \"\"\"\n    if isinstance(acc_data, pd.DataFrame):\n        acc_values = acc_data[['acc_x', 'acc_y', 'acc_z']].values.astype(float)\n    else:\n        acc_values = np.asarray(acc_data, dtype=float)\n\n    if isinstance(rot_data, pd.DataFrame):\n        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values.astype(float)\n    else:\n        quat_values = np.asarray(rot_data, dtype=float)\n\n    num_samples = acc_values.shape[0]\n    linear_accel = np.zeros_like(acc_values)\n    gravity_world = np.array([0.0, 0.0, 9.81], dtype=float)\n\n    for i in range(num_samples):\n        q = quat_values[i]\n        if q is None or np.any(np.isnan(q)) or np.allclose(q, 0.0):\n            linear_accel[i, :] = acc_values[i, :]\n            continue\n        try:\n            rotation = R.from_quat(q)\n            gravity_sensor_frame = rotation.apply(gravity_world, inverse=True)\n            linear_accel[i, :] = acc_values[i, :] - gravity_sensor_frame\n        except Exception:\n            linear_accel[i, :] = acc_values[i, :]\n    return linear_accel\n\n\ndef angular_velocity_from_quat_with_dt(quat_array, times=None, default_fs=200.0):\n    \"\"\"\n    quat_array: (N,4) array in order (rot_x,rot_y,rot_z,rot_w)\n    times: optional (N,) timestamps in seconds (or ms; function will normalize)\n    default_fs: fallback sampling rate in Hz\n    Returns angular_vel (N,3) where last row is zero.\n    \"\"\"\n    quat_array = np.asarray(quat_array, dtype=float)\n    N = quat_array.shape[0]\n    ang_vel = np.zeros((N, 3), dtype=float)\n    if N < 2:\n        return ang_vel\n\n    if times is not None:\n        t = np.asarray(times, dtype=float)\n        # heuristic: if timestamps look like epoch ms -> convert\n        if np.nanmean(t) > 1e6:\n            t = t / 1000.0\n        dt = np.diff(t)\n        # handle non-positive dt\n        pos = dt[dt > 0]\n        if pos.size == 0:\n            median_dt = 1.0 / default_fs\n        else:\n            median_dt = np.median(pos)\n        dt = np.where(dt > 0, dt, median_dt)\n    else:\n        dt = np.full(N-1, 1.0 / default_fs)\n\n    for i in range(N-1):\n        q_t = quat_array[i]\n        q_tp1 = quat_array[i+1]\n        if (np.any(np.isnan(q_t)) or np.allclose(q_t, 0.0)) or \\\n           (np.any(np.isnan(q_tp1)) or np.allclose(q_tp1, 0.0)):\n            continue\n        try:\n            r_t = R.from_quat(q_t)\n            r_tp1 = R.from_quat(q_tp1)\n            delta = r_t.inv() * r_tp1\n            rotvec = delta.as_rotvec()\n            ang_vel[i, :] = rotvec / dt[i]\n        except Exception:\n            # keep zeros on failure\n            pass\n    return ang_vel\n\n\ndef calculate_angular_distance_with_times(quat_array, times=None):\n    \"\"\"\n    Compute per-sample angular distance (angle between consecutive orientations).\n    Returns array shape (N,) with last element 0.\n    \"\"\"\n    quat_array = np.asarray(quat_array, dtype=float)\n    N = quat_array.shape[0]\n    ang_dist = np.zeros(N, dtype=float)\n    if N < 2:\n        return ang_dist\n\n    for i in range(N-1):\n        q1 = quat_array[i]\n        q2 = quat_array[i+1]\n        if (np.any(np.isnan(q1)) or np.allclose(q1, 0.0)) or \\\n           (np.any(np.isnan(q2)) or np.allclose(q2, 0.0)):\n            ang_dist[i] = 0.0\n            continue\n        try:\n            r1 = R.from_quat(q1)\n            r2 = R.from_quat(q2)\n            relative = r1.inv() * r2\n            ang_dist[i] = np.linalg.norm(relative.as_rotvec())\n        except Exception:\n            ang_dist[i] = 0.0\n    return ang_dist\n\n# -------------------------\n# Vectorized ToF region stats (avoids fragmentation/warnings)\n# -------------------------\ndef compute_tof_region_stats_matrix(subdf_mat, modes):\n    \"\"\"\n    subdf_mat: numpy array shape (N,64) with NaNs for missing values\n    modes: list of ints, e.g. [4] or [2,4,8,16,32]\n    Returns dict mapping column_name -> ndarray (N,)\n    \"\"\"\n    new_cols = {}\n    mat = subdf_mat.astype(float)  # (N,64)\n    with np.errstate(invalid='ignore'):\n        new_cols[\"mean\"] = np.nanmean(mat, axis=1)\n        new_cols[\"std\"]  = np.nanstd(mat, axis=1)\n        new_cols[\"min\"]  = np.nanmin(mat, axis=1)\n        new_cols[\"max\"]  = np.nanmax(mat, axis=1)\n\n    flat = mat.reshape(-1, 64)\n    for mode in modes:\n        if mode <= 0:\n            continue\n        region_size = 64 // mode if mode>0 and 64%mode==0 else max(1, 64 // mode)\n        for r in range(mode):\n            start = r * region_size\n            end = start + region_size if (r < mode-1) else 64\n            region_vals = flat[:, start:end]\n            with np.errstate(all='ignore'):\n                mean_v = np.nanmean(region_vals, axis=1)\n                std_v  = np.nanstd(region_vals, axis=1)\n                min_v  = np.nanmin(region_vals, axis=1)\n                max_v  = np.nanmax(region_vals, axis=1)\n            # keys will be filled by caller with tofid prefix\n            new_cols[f\"r{mode}_{r}_mean\"] = mean_v\n            new_cols[f\"r{mode}_{r}_std\"]  = std_v\n            new_cols[f\"r{mode}_{r}_min\"]  = min_v\n            new_cols[f\"r{mode}_{r}_max\"]  = max_v\n    return new_cols\n\n\ndef add_all_tof_features_vectorized(df, tof_mode):\n    \"\"\"\n    For each tof sensor 1..5, compute:\n      tof_{i}_mean/std/min/max\n      and for each mode in modes: tof{mode}_{i}_region_{r}_{stat}\n    Returns a new DataFrame = pd.concat([df, new_cols_df], axis=1)\n    \"\"\"\n    if tof_mode == 0:\n        modes = []\n    elif tof_mode == -1:\n        modes = [2,4,8,16,32]\n    else:\n        modes = [tof_mode]\n\n    all_new = {}\n    N = len(df)\n    for tof_id in range(1, 6):\n        tof_cols = [f\"tof_{tof_id}_v{p}\" for p in range(64)]\n        # ensure columns exist (create NaN if missing)\n        for c in tof_cols:\n            if c not in df.columns:\n                df[c] = np.nan\n\n        subdf = df[tof_cols].astype(float).replace(-1, np.nan)\n        mat = subdf.values  # (N,64)\n        new = compute_tof_region_stats_matrix(mat, modes)\n        # prefix names and add to all_new\n        all_new[f\"tof_{tof_id}_mean\"] = new[\"mean\"]\n        all_new[f\"tof_{tof_id}_std\"]  = new[\"std\"]\n        all_new[f\"tof_{tof_id}_min\"]  = new[\"min\"]\n        all_new[f\"tof_{tof_id}_max\"]  = new[\"max\"]\n        for mode in modes:\n            for r in range(mode):\n                all_new[f\"tof{mode}_{tof_id}_region_{r}_mean\"] = new[f\"r{mode}_{r}_mean\"]\n                all_new[f\"tof{mode}_{tof_id}_region_{r}_std\"]  = new[f\"r{mode}_{r}_std\"]\n                all_new[f\"tof{mode}_{tof_id}_region_{r}_min\"]  = new[f\"r{mode}_{r}_min\"]\n                all_new[f\"tof{mode}_{tof_id}_region_{r}_max\"]  = new[f\"r{mode}_{r}_max\"]\n\n    # concat once\n    new_df = pd.concat([df, pd.DataFrame(all_new, index=df.index)], axis=1)\n    return new_df\n\n# -------------------------\n# Utility: estimate per-sequence timestamps (seconds)\n# -------------------------\ndef get_sequence_times(group_df, time_col='timestamp'):\n    \"\"\"\n    Returns times array in seconds if available, else None.\n    If timestamps appear to be epoch-ms, convert to seconds.\n    \"\"\"\n    if time_col in group_df.columns:\n        times = group_df[time_col].astype(float).values\n        if np.nanmean(times) > 1e6:\n            times = times / 1000.0\n        return times\n    return None\n\n# -------------------------\n# Main pipeline\n# -------------------------\ndef make_universe_csv(raw_csv_path,\n                      out_csv_path=\"universe.csv\",\n                      tof_mode=16,\n                      default_fs=200.0,\n                      time_col='timestamp',\n                      tof_raw_keep=True):\n    \"\"\"\n    raw_csv_path: path to raw csv (one row per timestamp). Must include sequence_id and sensor columns.\n    out_csv_path: final CSV file for CMIFeDataset\n    tof_mode: same behavior as CMIFeDataset (0, >1, or -1)\n    default_fs: fallback sampling rate for angular velocity if no timestamps present\n    time_col: name of timestamp column if present (optional)\n    tof_raw_keep: if True keep raw tof_*_v* columns (recommended)\n    \"\"\"\n    print(\"Loading raw CSV:\", raw_csv_path)\n    df_raw = pd.read_csv(raw_csv_path)\n    print(\"Raw shape:\", df_raw.shape)\n\n    # Prepare base: ensure sequence_id present\n    if 'sequence_id' not in df_raw.columns:\n        raise ValueError(\"Raw CSV must contain 'sequence_id' column.\")\n\n    df = df_raw.copy()\n\n    # ensure base columns exist to avoid KeyError downstream\n    for col in ['acc_x','acc_y','acc_z','rot_x','rot_y','rot_z','rot_w']:\n        if col not in df.columns:\n            df[col] = np.nan\n    # ensure thermal columns exist: thm_1..thm_5\n    for i in range(1,6):\n        c = f\"thm_{i}\"\n        if c not in df.columns:\n            df[c] = np.nan\n\n    # ----- IMU: acc_mag, rot_angle (vectorized) -----\n    with np.errstate(invalid='ignore'):\n        df['acc_mag'] = np.sqrt(df['acc_x'].astype(float)**2 + df['acc_y'].astype(float)**2 + df['acc_z'].astype(float)**2)\n        df['rot_angle'] = 2 * np.arccos(df['rot_w'].astype(float).clip(-1,1))\n\n    # compute acc_mag_jerk and rot_angle_vel by group (vectorized groupby diff)\n    df['acc_mag_jerk'] = df.groupby('sequence_id')['acc_mag'].diff().fillna(0)\n    df['rot_angle_vel'] = df.groupby('sequence_id')['rot_angle'].diff().fillna(0)\n\n    # ----- Linear accel (remove gravity) per sequence -----\n    N = len(df)\n    lin_x = np.full(N, np.nan, dtype=float)\n    lin_y = np.full(N, np.nan, dtype=float)\n    lin_z = np.full(N, np.nan, dtype=float)\n\n    if all(c in df.columns for c in ['acc_x','acc_y','acc_z','rot_x','rot_y','rot_z','rot_w']):\n        print(\"Computing gravity-removed linear acceleration per sequence...\")\n        for seq_id, group in tqdm(df.groupby('sequence_id'), desc=\"linear_acc\"):\n            idx = group.index\n            acc_sub = group[['acc_x','acc_y','acc_z']].astype(float)\n            rot_sub = group[['rot_x','rot_y','rot_z','rot_w']].astype(float)\n            la = remove_gravity_from_acc(acc_sub, rot_sub)\n            lin_x[idx] = la[:,0]\n            lin_y[idx] = la[:,1]\n            lin_z[idx] = la[:,2]\n    else:\n        warnings.warn(\"Rotation or accelerometer columns missing; using raw acc with gravity approx.\")\n        if 'acc_x' in df.columns:\n            lin_x[:] = df['acc_x'].astype(float).fillna(0.0)\n        if 'acc_y' in df.columns:\n            lin_y[:] = df['acc_y'].astype(float).fillna(0.0)\n        if 'acc_z' in df.columns:\n            lin_z[:] = df['acc_z'].astype(float).fillna(0.0) - 9.81\n\n    df['linear_acc_x'] = lin_x\n    df['linear_acc_y'] = lin_y\n    df['linear_acc_z'] = lin_z\n    df['linear_acc_mag'] = np.sqrt(np.nan_to_num(df['linear_acc_x'])**2 + np.nan_to_num(df['linear_acc_y'])**2 + np.nan_to_num(df['linear_acc_z'])**2)\n    df['linear_acc_mag_jerk'] = df.groupby('sequence_id')['linear_acc_mag'].diff().fillna(0)\n\n    # ----- Angular velocity & angular distance by sequence using timestamps if available -----\n    N = len(df)\n    av_x = np.zeros(N, dtype=float)\n    av_y = np.zeros(N, dtype=float)\n    av_z = np.zeros(N, dtype=float)\n    ang_dist = np.zeros(N, dtype=float)\n\n    if all(c in df.columns for c in ['rot_x','rot_y','rot_z','rot_w']):\n        print(\"Computing angular velocity & angular distance per sequence...\")\n        for seq_id, group in tqdm(df.groupby('sequence_id'), desc=\"ang_vel\"):\n            idx = group.index\n            quat_arr = group[['rot_x','rot_y','rot_z','rot_w']].astype(float).values\n            times = get_sequence_times(group, time_col=time_col)  # None if missing\n            ang_vel = angular_velocity_from_quat_with_dt(quat_arr, times=times, default_fs=default_fs)\n            ad = calculate_angular_distance_with_times(quat_arr, times=times)\n            av_x[idx] = ang_vel[:,0]\n            av_y[idx] = ang_vel[:,1]\n            av_z[idx] = ang_vel[:,2]\n            ang_dist[idx] = ad\n    else:\n        warnings.warn(\"Rotation quaternion columns missing -> angular velocity/distance set to 0.\")\n\n    df['angular_vel_x'] = av_x\n    df['angular_vel_y'] = av_y\n    df['angular_vel_z'] = av_z\n    df['angular_distance'] = ang_dist\n\n    # Fill any remaining NaNs in engineered IMU with zeros (ensures columns exist)\n    imu_engineered = ['acc_mag','rot_angle','acc_mag_jerk','rot_angle_vel',\n                      'linear_acc_x','linear_acc_y','linear_acc_z',\n                      'linear_acc_mag','linear_acc_mag_jerk',\n                      'angular_vel_x','angular_vel_y','angular_vel_z',\n                      'angular_distance']\n    for c in imu_engineered:\n        if c not in df.columns:\n            df[c] = 0.0\n        else:\n            df[c] = df[c].fillna(0.0)\n\n    # ----- Thermal basic stats (optional) -----\n    thm_cols = [f\"thm_{i}\" for i in range(1,6)]\n    present_thm = [c for c in thm_cols if c in df.columns]\n    if present_thm:\n        df['thm_mean'] = df[present_thm].astype(float).mean(axis=1)\n        df['thm_std']  = df[present_thm].astype(float).std(axis=1).fillna(0.0)\n    else:\n        warnings.warn(\"Thermal columns thm_1..thm_5 not found.\")\n\n    # ----- ToF features (vectorized, concat once) -----\n    print(\"Computing ToF features (this may take a moment for large files)...\")\n    df = add_all_tof_features_vectorized(df, tof_mode)\n\n    # Optionally drop raw tof columns (not recommended for baseline)\n    if not tof_raw_keep:\n        for tof_id in range(1,6):\n            for p in range(64):\n                c = f\"tof_{tof_id}_v{p}\"\n                if c in df.columns:\n                    df.drop(columns=[c], inplace=True)\n\n    # Final save\n    print(\"Final dataframe shape:\", df.shape)\n    df.to_csv(out_csv_path, index=False)\n    print(\"Saved universe CSV to:\", out_csv_path)\n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T10:53:03.441992Z","iopub.execute_input":"2025-09-01T10:53:03.442225Z","iopub.status.idle":"2025-09-01T10:53:03.476127Z","shell.execute_reply.started":"2025-09-01T10:53:03.442200Z","shell.execute_reply":"2025-09-01T10:53:03.475474Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"if __name__ == \"__main__\": \n    RAW_CSV = data_path      \n    OUT_CSV = \"/kaggle/working/train_universe.csv\"     \n    TOF_MODE = 16                  # set to same value your dataset config uses (e.g. 4,8,16) or -1 for [2,4,8,16,32]\n    DEFAULT_FS = 200.0             \n\n    # run\n    universe_df = make_universe_csv(RAW_CSV, OUT_CSV, tof_mode=TOF_MODE, default_fs=DEFAULT_FS, time_col='timestamp', tof_raw_keep=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T10:53:03.476861Z","iopub.execute_input":"2025-09-01T10:53:03.477239Z","iopub.status.idle":"2025-09-01T11:01:13.683103Z","shell.execute_reply.started":"2025-09-01T10:53:03.477206Z","shell.execute_reply":"2025-09-01T11:01:13.682453Z"}},"outputs":[{"name":"stdout","text":"Loading raw CSV: /kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv\nRaw shape: (574945, 341)\nComputing gravity-removed linear acceleration per sequence...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"linear_acc:   0%|          | 0/8151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e81f4371ec641faaec4223d88fb83f1"}},"metadata":{}},{"name":"stdout","text":"Computing angular velocity & angular distance per sequence...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"ang_vel:   0%|          | 0/8151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"132610cef1ac4dc5b63c080b127c56d2"}},"metadata":{}},{"name":"stdout","text":"Computing ToF features (this may take a moment for large files)...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/372090662.py:127: RuntimeWarning: Mean of empty slice\n  new_cols[\"mean\"] = np.nanmean(mat, axis=1)\n/usr/local/lib/python3.11/dist-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n/tmp/ipykernel_36/372090662.py:129: RuntimeWarning: All-NaN slice encountered\n  new_cols[\"min\"]  = np.nanmin(mat, axis=1)\n/tmp/ipykernel_36/372090662.py:130: RuntimeWarning: All-NaN slice encountered\n  new_cols[\"max\"]  = np.nanmax(mat, axis=1)\n/tmp/ipykernel_36/372090662.py:142: RuntimeWarning: Mean of empty slice\n  mean_v = np.nanmean(region_vals, axis=1)\n/tmp/ipykernel_36/372090662.py:144: RuntimeWarning: All-NaN slice encountered\n  min_v  = np.nanmin(region_vals, axis=1)\n/tmp/ipykernel_36/372090662.py:145: RuntimeWarning: All-NaN slice encountered\n  max_v  = np.nanmax(region_vals, axis=1)\n/tmp/ipykernel_36/372090662.py:127: RuntimeWarning: Mean of empty slice\n  new_cols[\"mean\"] = np.nanmean(mat, axis=1)\n/usr/local/lib/python3.11/dist-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n/tmp/ipykernel_36/372090662.py:129: RuntimeWarning: All-NaN slice encountered\n  new_cols[\"min\"]  = np.nanmin(mat, axis=1)\n/tmp/ipykernel_36/372090662.py:130: RuntimeWarning: All-NaN slice encountered\n  new_cols[\"max\"]  = np.nanmax(mat, axis=1)\n/tmp/ipykernel_36/372090662.py:142: RuntimeWarning: Mean of empty slice\n  mean_v = np.nanmean(region_vals, axis=1)\n/tmp/ipykernel_36/372090662.py:144: RuntimeWarning: All-NaN slice encountered\n  min_v  = np.nanmin(region_vals, axis=1)\n/tmp/ipykernel_36/372090662.py:145: RuntimeWarning: All-NaN slice encountered\n  max_v  = np.nanmax(region_vals, axis=1)\n/tmp/ipykernel_36/372090662.py:127: RuntimeWarning: Mean of empty slice\n  new_cols[\"mean\"] = np.nanmean(mat, axis=1)\n/usr/local/lib/python3.11/dist-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n/tmp/ipykernel_36/372090662.py:129: RuntimeWarning: All-NaN slice encountered\n  new_cols[\"min\"]  = np.nanmin(mat, axis=1)\n/tmp/ipykernel_36/372090662.py:130: RuntimeWarning: All-NaN slice encountered\n  new_cols[\"max\"]  = np.nanmax(mat, axis=1)\n/tmp/ipykernel_36/372090662.py:142: RuntimeWarning: Mean of empty slice\n  mean_v = np.nanmean(region_vals, axis=1)\n/tmp/ipykernel_36/372090662.py:144: RuntimeWarning: All-NaN slice encountered\n  min_v  = np.nanmin(region_vals, axis=1)\n/tmp/ipykernel_36/372090662.py:145: RuntimeWarning: All-NaN slice encountered\n  max_v  = np.nanmax(region_vals, axis=1)\n/tmp/ipykernel_36/372090662.py:127: RuntimeWarning: Mean of empty slice\n  new_cols[\"mean\"] = np.nanmean(mat, axis=1)\n/usr/local/lib/python3.11/dist-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n/tmp/ipykernel_36/372090662.py:129: RuntimeWarning: All-NaN slice encountered\n  new_cols[\"min\"]  = np.nanmin(mat, axis=1)\n/tmp/ipykernel_36/372090662.py:130: RuntimeWarning: All-NaN slice encountered\n  new_cols[\"max\"]  = np.nanmax(mat, axis=1)\n/tmp/ipykernel_36/372090662.py:142: RuntimeWarning: Mean of empty slice\n  mean_v = np.nanmean(region_vals, axis=1)\n/tmp/ipykernel_36/372090662.py:144: RuntimeWarning: All-NaN slice encountered\n  min_v  = np.nanmin(region_vals, axis=1)\n/tmp/ipykernel_36/372090662.py:145: RuntimeWarning: All-NaN slice encountered\n  max_v  = np.nanmax(region_vals, axis=1)\n/tmp/ipykernel_36/372090662.py:127: RuntimeWarning: Mean of empty slice\n  new_cols[\"mean\"] = np.nanmean(mat, axis=1)\n/usr/local/lib/python3.11/dist-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n/tmp/ipykernel_36/372090662.py:129: RuntimeWarning: All-NaN slice encountered\n  new_cols[\"min\"]  = np.nanmin(mat, axis=1)\n/tmp/ipykernel_36/372090662.py:130: RuntimeWarning: All-NaN slice encountered\n  new_cols[\"max\"]  = np.nanmax(mat, axis=1)\n/tmp/ipykernel_36/372090662.py:142: RuntimeWarning: Mean of empty slice\n  mean_v = np.nanmean(region_vals, axis=1)\n/tmp/ipykernel_36/372090662.py:144: RuntimeWarning: All-NaN slice encountered\n  min_v  = np.nanmin(region_vals, axis=1)\n/tmp/ipykernel_36/372090662.py:145: RuntimeWarning: All-NaN slice encountered\n  max_v  = np.nanmax(region_vals, axis=1)\n","output_type":"stream"},{"name":"stdout","text":"Final dataframe shape: (574945, 696)\nSaved universe CSV to: /kaggle/working/train_universe.csv\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"universe_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T11:01:13.683786Z","iopub.execute_input":"2025-09-01T11:01:13.684047Z","iopub.status.idle":"2025-09-01T11:01:13.712801Z","shell.execute_reply.started":"2025-09-01T11:01:13.684021Z","shell.execute_reply":"2025-09-01T11:01:13.712231Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"              row_id sequence_type sequence_id  sequence_counter      subject  \\\n0  SEQ_000007_000000        Target  SEQ_000007                 0  SUBJ_059520   \n1  SEQ_000007_000001        Target  SEQ_000007                 1  SUBJ_059520   \n2  SEQ_000007_000002        Target  SEQ_000007                 2  SUBJ_059520   \n3  SEQ_000007_000003        Target  SEQ_000007                 3  SUBJ_059520   \n4  SEQ_000007_000004        Target  SEQ_000007                 4  SUBJ_059520   \n\n                       orientation                                   behavior  \\\n0  Seated Lean Non Dom - FACE DOWN  Relaxes and moves hand to target location   \n1  Seated Lean Non Dom - FACE DOWN  Relaxes and moves hand to target location   \n2  Seated Lean Non Dom - FACE DOWN  Relaxes and moves hand to target location   \n3  Seated Lean Non Dom - FACE DOWN  Relaxes and moves hand to target location   \n4  Seated Lean Non Dom - FACE DOWN  Relaxes and moves hand to target location   \n\n        phase             gesture     acc_x  ...  tof16_5_region_13_min  \\\n0  Transition  Cheek - pinch skin  6.683594  ...                    NaN   \n1  Transition  Cheek - pinch skin  6.949219  ...                    NaN   \n2  Transition  Cheek - pinch skin  5.722656  ...                    NaN   \n3  Transition  Cheek - pinch skin  6.601562  ...                    NaN   \n4  Transition  Cheek - pinch skin  5.566406  ...                    NaN   \n\n   tof16_5_region_13_max  tof16_5_region_14_mean  tof16_5_region_14_std  \\\n0                    NaN                     NaN                    NaN   \n1                    NaN                     NaN                    NaN   \n2                    NaN              115.500000               3.500000   \n3                    NaN              106.000000               5.000000   \n4                    NaN              111.666667               9.977753   \n\n   tof16_5_region_14_min  tof16_5_region_14_max  tof16_5_region_15_mean  \\\n0                    NaN                    NaN                     NaN   \n1                    NaN                    NaN                     NaN   \n2                  112.0                  119.0                     NaN   \n3                  101.0                  111.0                     NaN   \n4                  101.0                  125.0                     NaN   \n\n   tof16_5_region_15_std  tof16_5_region_15_min  tof16_5_region_15_max  \n0                    NaN                    NaN                    NaN  \n1                    NaN                    NaN                    NaN  \n2                    NaN                    NaN                    NaN  \n3                    NaN                    NaN                    NaN  \n4                    NaN                    NaN                    NaN  \n\n[5 rows x 696 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>sequence_type</th>\n      <th>sequence_id</th>\n      <th>sequence_counter</th>\n      <th>subject</th>\n      <th>orientation</th>\n      <th>behavior</th>\n      <th>phase</th>\n      <th>gesture</th>\n      <th>acc_x</th>\n      <th>...</th>\n      <th>tof16_5_region_13_min</th>\n      <th>tof16_5_region_13_max</th>\n      <th>tof16_5_region_14_mean</th>\n      <th>tof16_5_region_14_std</th>\n      <th>tof16_5_region_14_min</th>\n      <th>tof16_5_region_14_max</th>\n      <th>tof16_5_region_15_mean</th>\n      <th>tof16_5_region_15_std</th>\n      <th>tof16_5_region_15_min</th>\n      <th>tof16_5_region_15_max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SEQ_000007_000000</td>\n      <td>Target</td>\n      <td>SEQ_000007</td>\n      <td>0</td>\n      <td>SUBJ_059520</td>\n      <td>Seated Lean Non Dom - FACE DOWN</td>\n      <td>Relaxes and moves hand to target location</td>\n      <td>Transition</td>\n      <td>Cheek - pinch skin</td>\n      <td>6.683594</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SEQ_000007_000001</td>\n      <td>Target</td>\n      <td>SEQ_000007</td>\n      <td>1</td>\n      <td>SUBJ_059520</td>\n      <td>Seated Lean Non Dom - FACE DOWN</td>\n      <td>Relaxes and moves hand to target location</td>\n      <td>Transition</td>\n      <td>Cheek - pinch skin</td>\n      <td>6.949219</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SEQ_000007_000002</td>\n      <td>Target</td>\n      <td>SEQ_000007</td>\n      <td>2</td>\n      <td>SUBJ_059520</td>\n      <td>Seated Lean Non Dom - FACE DOWN</td>\n      <td>Relaxes and moves hand to target location</td>\n      <td>Transition</td>\n      <td>Cheek - pinch skin</td>\n      <td>5.722656</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>115.500000</td>\n      <td>3.500000</td>\n      <td>112.0</td>\n      <td>119.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SEQ_000007_000003</td>\n      <td>Target</td>\n      <td>SEQ_000007</td>\n      <td>3</td>\n      <td>SUBJ_059520</td>\n      <td>Seated Lean Non Dom - FACE DOWN</td>\n      <td>Relaxes and moves hand to target location</td>\n      <td>Transition</td>\n      <td>Cheek - pinch skin</td>\n      <td>6.601562</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>106.000000</td>\n      <td>5.000000</td>\n      <td>101.0</td>\n      <td>111.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SEQ_000007_000004</td>\n      <td>Target</td>\n      <td>SEQ_000007</td>\n      <td>4</td>\n      <td>SUBJ_059520</td>\n      <td>Seated Lean Non Dom - FACE DOWN</td>\n      <td>Relaxes and moves hand to target location</td>\n      <td>Transition</td>\n      <td>Cheek - pinch skin</td>\n      <td>5.566406</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>111.666667</td>\n      <td>9.977753</td>\n      <td>101.0</td>\n      <td>125.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 696 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# CMIFEDataset Class inheriting base Dataset Class\nclass CMIFeDataset(Dataset):\n    def __init__(self, data_path, config):\n        self.config = config\n        self.init_feature_names(data_path)\n        df = self.generate_features(pd.read_csv(data_path, usecols=set(self.base_cols+self.feature_cols)))\n        self.generate_dataset(df)\n\n    def init_feature_names(self, data_path):\n        self.imu_engineered_features = [\n            'acc_mag', 'rot_angle',\n            'acc_mag_jerk', 'rot_angle_vel',\n            'linear_acc_mag', 'linear_acc_mag_jerk',\n            'angular_vel_x', 'angular_vel_y', 'angular_vel_z',\n            'angular_distance'\n        ]\n\n        self.tof_mode = self.config.get(\"tof_mode\", \"stats\")\n        self.tof_region_stats = ['mean', 'std', 'min', 'max']\n        self.tof_cols = self.generate_tof_feature_names()\n\n        columns = pd.read_csv(data_path, nrows=0).columns.tolist()\n        imu_cols_base = ['linear_acc_x', 'linear_acc_y', 'linear_acc_z']\n        imu_cols_base.extend([c for c in columns if c.startswith('rot_') and c not in ['rot_angle', 'rot_angle_vel']])\n        self.imu_cols = list(dict.fromkeys(imu_cols_base + self.imu_engineered_features))\n        self.thm_cols = [c for c in columns if c.startswith('thm_')]\n        self.feature_cols = self.imu_cols + self.thm_cols + self.tof_cols\n        self.imu_dim = len(self.imu_cols)\n        self.thm_dim = len(self.thm_cols)\n        self.tof_dim = len(self.tof_cols)\n        self.base_cols = ['acc_x', 'acc_y', 'acc_z',\n                          'rot_x', 'rot_y', 'rot_z', 'rot_w',\n                          'sequence_id', 'subject', \n                          'sequence_type', 'gesture', 'orientation'] + [c for c in columns if c.startswith('thm_')] + [f\"tof_{i}_v{p}\" for i in range(1, 6) for p in range(64)]\n        self.fold_cols = ['subject', 'sequence_type', 'gesture', 'orientation']\n\n    def generate_tof_feature_names(self):\n        features = []\n        if self.config.get(\"tof_raw\", False):\n            for i in range(1, 6):\n                features.extend([f\"tof_{i}_v{p}\" for p in range(64)])\n        for i in range(1, 6):\n            if self.tof_mode != 0:\n                for stat in self.tof_region_stats:\n                    features.append(f'tof_{i}_{stat}')\n                if self.tof_mode > 1:\n                    for r in range(self.tof_mode):\n                        for stat in self.tof_region_stats:\n                            features.append(f'tof{self.tof_mode}_{i}_region_{r}_{stat}')\n                if self.tof_mode == -1:\n                    for mode in [2, 4, 8, 16, 32]:\n                        for r in range(mode):\n                            for stat in self.tof_region_stats:\n                                features.append(f'tof{mode}_{i}_region_{r}_{stat}')\n        return features\n\n    def compute_features(self, df):\n        df['acc_mag'] = np.sqrt(df['acc_x']**2 + df['acc_y']**2 + df['acc_z']**2)\n        df['rot_angle'] = 2 * np.arccos(df['rot_w'].clip(-1, 1))\n        df['acc_mag_jerk'] = df.groupby('sequence_id')['acc_mag'].diff().fillna(0)\n        df['rot_angle_vel'] = df.groupby('sequence_id')['rot_angle'].diff().fillna(0)\n            \n        linear_accel_list = []\n        for _, group in df.groupby('sequence_id'):\n            acc_data_group = group[['acc_x', 'acc_y', 'acc_z']]\n            rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n            linear_accel_group = remove_gravity_from_acc(acc_data_group, rot_data_group)\n            linear_accel_list.append(pd.DataFrame(linear_accel_group, columns=['linear_acc_x', 'linear_acc_y', 'linear_acc_z'], index=group.index))\n        df_linear_accel = pd.concat(linear_accel_list)\n        df = pd.concat([df, df_linear_accel], axis=1)\n        df['linear_acc_mag'] = np.sqrt(df['linear_acc_x']**2 + df['linear_acc_y']**2 + df['linear_acc_z']**2)\n        df['linear_acc_mag_jerk'] = df.groupby('sequence_id')['linear_acc_mag'].diff().fillna(0)\n    \n        angular_vel_list = []\n        for _, group in df.groupby('sequence_id'):\n            rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n            angular_vel_group = calculate_angular_velocity_from_quat(rot_data_group)\n            angular_vel_list.append(pd.DataFrame(angular_vel_group, columns=['angular_vel_x', 'angular_vel_y', 'angular_vel_z'], index=group.index))\n        df_angular_vel = pd.concat(angular_vel_list)\n        df = pd.concat([df, df_angular_vel], axis=1)\n    \n        angular_distance_list = []\n        for _, group in df.groupby('sequence_id'):\n            rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n            angular_dist_group = calculate_angular_distance(rot_data_group)\n            angular_distance_list.append(pd.DataFrame(angular_dist_group, columns=['angular_distance'], index=group.index))\n        df_angular_distance = pd.concat(angular_distance_list)\n        df = pd.concat([df, df_angular_distance], axis=1)\n\n        if self.tof_mode != 0:\n            new_columns = {}\n            for i in range(1, 6):\n                pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]\n                tof_data = df[pixel_cols].replace(-1, np.nan)\n                new_columns.update({\n                    f'tof_{i}_mean': tof_data.mean(axis=1),\n                    f'tof_{i}_std': tof_data.std(axis=1),\n                    f'tof_{i}_min': tof_data.min(axis=1),\n                    f'tof_{i}_max': tof_data.max(axis=1)\n                })\n                if self.tof_mode > 1:\n                    region_size = 64 // self.tof_mode\n                    for r in range(self.tof_mode):\n                        region_data = tof_data.iloc[:, r*region_size : (r+1)*region_size]\n                        new_columns.update({\n                            f'tof{self.tof_mode}_{i}_region_{r}_mean': region_data.mean(axis=1),\n                            f'tof{self.tof_mode}_{i}_region_{r}_std': region_data.std(axis=1),\n                            f'tof{self.tof_mode}_{i}_region_{r}_min': region_data.min(axis=1),\n                            f'tof{self.tof_mode}_{i}_region_{r}_max': region_data.max(axis=1)\n                        })\n                if self.tof_mode == -1:\n                    for mode in [2, 4, 8, 16, 32]:\n                        region_size = 64 // mode\n                        for r in range(mode):\n                            region_data = tof_data.iloc[:, r*region_size : (r+1)*region_size]\n                            new_columns.update({\n                                f'tof{mode}_{i}_region_{r}_mean': region_data.mean(axis=1),\n                                f'tof{mode}_{i}_region_{r}_std': region_data.std(axis=1),\n                                f'tof{mode}_{i}_region_{r}_min': region_data.min(axis=1),\n                                f'tof{mode}_{i}_region_{r}_max': region_data.max(axis=1)\n                            })\n            df = pd.concat([df, pd.DataFrame(new_columns)], axis=1)\n        return df\n        \n    def generate_features(self, df):\n        self.le = LabelEncoder()\n        df['gesture_int'] = self.le.fit_transform(df['gesture'])\n        self.class_num = len(self.le.classes_)\n\n        joblib.dump(self.le, \"label_encoder.pkl\")\n        \n        if all(c in df.columns for c in self.imu_engineered_features) and all(c in df.columns for c in self.tof_cols):\n            print(\"Have precomputed, skip compute.\")\n        else:\n            print(\"Not precomputed, do compute.\")\n            df = self.compute_features(df)\n\n        if self.config.get(\"save_precompute\", False):\n            df.to_csv(self.config.get(\"save_filename\", \"train.csv\"))\n        return df\n\n    def scale(self, data_unscaled):\n        scaler_function = self.config.get(\"scaler_function\", StandardScaler())\n        scaler = scaler_function.fit(np.concatenate(data_unscaled, axis=0))\n        return [scaler.transform(x) for x in data_unscaled], scaler\n\n    def pad(self, data_scaled, cols):\n        pad_data = np.zeros((len(data_scaled), self.pad_len, len(cols)), dtype='float32')\n        for i, seq in enumerate(data_scaled):\n            seq_len = min(len(seq), self.pad_len)\n            pad_data[i, :seq_len] = seq[:seq_len]\n        return pad_data\n\n    def get_nan_value(self, data, ratio):\n        max_value = data.max().max()\n        nan_value = -max_value * ratio\n        return nan_value\n\n    def generate_dataset(self, df):\n        seq_gp = df.groupby('sequence_id') \n        imu_unscaled, thm_unscaled, tof_unscaled = [], [], []\n        classes, lens = [], []\n        self.imu_nan_value = self.get_nan_value(df[self.imu_cols], self.config[\"nan_ratio\"][\"imu\"])\n        self.thm_nan_value = self.get_nan_value(df[self.thm_cols], self.config[\"nan_ratio\"][\"thm\"])\n        self.tof_nan_value = self.get_nan_value(df[self.tof_cols], self.config[\"nan_ratio\"][\"tof\"])\n\n        self.fold_feats = defaultdict(list)\n        for seq_id, seq_df in seq_gp:\n            imu_data = seq_df[self.imu_cols]\n            if self.config[\"fbfill\"][\"imu\"]:\n                imu_data = imu_data.ffill().bfill()\n            imu_unscaled.append(imu_data.fillna(self.imu_nan_value).values.astype('float32'))\n\n            thm_data = seq_df[self.thm_cols]\n            if self.config[\"fbfill\"][\"thm\"]:\n                thm_data = thm_data.ffill().bfill()\n            thm_unscaled.append(thm_data.fillna(self.thm_nan_value).values.astype('float32'))\n\n            tof_data = seq_df[self.tof_cols]\n            if self.config[\"fbfill\"][\"tof\"]:\n                tof_data = tof_data.ffill().bfill()\n            tof_unscaled.append(tof_data.fillna(self.tof_nan_value).values.astype('float32'))\n            \n            classes.append(seq_df['gesture_int'].iloc[0])\n            lens.append(len(imu_data))\n\n            for col in self.fold_cols:\n                self.fold_feats[col].append(seq_df[col].iloc[0])\n            \n        self.dataset_indices = classes\n        self.pad_len = int(np.percentile(lens, self.config.get(\"percent\", 95)))\n        if self.config.get(\"one_scale\", True):\n            x_unscaled = [np.concatenate([imu, thm, tof], axis=1) for imu, thm, tof in zip(imu_unscaled, thm_unscaled, tof_unscaled)]\n            x_scaled, self.x_scaler = self.scale(x_unscaled)\n            x = self.pad(x_scaled, self.imu_cols+self.thm_cols+self.tof_cols)\n            self.imu = x[..., :self.imu_dim]\n            self.thm = x[..., self.imu_dim:self.imu_dim+self.thm_dim]\n            self.tof = x[..., self.imu_dim+self.thm_dim:self.imu_dim+self.thm_dim+self.tof_dim]\n        else:\n            imu_scaled, self.imu_scaler = self.scale(imu_unscaled)\n            thm_scaled, self.thm_scaler = self.scale(thm_unscaled)\n            tof_scaled, self.tof_scaler = self.scale(tof_unscaled)\n            self.imu = self.pad(imu_scaled, self.imu_cols)\n            self.thm = self.pad(thm_scaled, self.thm_cols)\n            self.tof = self.pad(tof_scaled, self.tof_cols)\n        self.precompute_scaled_nan_values()\n        self.class_ = F.one_hot(torch.from_numpy(np.array(classes)).long(), num_classes=len(self.le.classes_)).float().numpy()\n        self.class_weight = torch.FloatTensor(compute_class_weight('balanced', classes=np.arange(len(self.le.classes_)), y=classes))\n\n    def precompute_scaled_nan_values(self):\n        dummy_df = pd.DataFrame(\n            np.array([[self.imu_nan_value]*len(self.imu_cols) + \n                     [self.thm_nan_value]*len(self.thm_cols) +\n                     [self.tof_nan_value]*len(self.tof_cols)]),\n            columns=self.imu_cols + self.thm_cols + self.tof_cols\n        )\n        \n        if self.config.get(\"one_scale\", True):\n            scaled = self.x_scaler.transform(dummy_df)\n            self.imu_scaled_nan = scaled[0, :self.imu_dim].mean()\n            self.thm_scaled_nan = scaled[0, self.imu_dim:self.imu_dim+self.thm_dim].mean()\n            self.tof_scaled_nan = scaled[0, self.imu_dim+self.thm_dim:self.imu_dim+self.thm_dim+self.tof_dim].mean()\n        else:\n            self.imu_scaled_nan = self.imu_scaler.transform(dummy_df[self.imu_cols])[0].mean()\n            self.thm_scaled_nan = self.thm_scaler.transform(dummy_df[self.thm_cols])[0].mean()\n            self.tof_scaled_nan = self.tof_scaler.transform(dummy_df[self.tof_cols])[0].mean()\n\n    def get_scaled_nan_tensors(self, imu, thm, tof):\n        return torch.full(imu.shape, self.imu_scaled_nan, device=imu.device), \\\n            torch.full(thm.shape, self.thm_scaled_nan, device=thm.device), \\\n            torch.full(tof.shape, self.tof_scaled_nan, device=tof.device)\n\n    def inference_process(self, sequence):\n        df_seq = sequence#.to_pandas().copy()\n        if not all(c in df_seq.columns for c in self.imu_engineered_features):\n            df_seq['acc_mag'] = np.sqrt(df_seq['acc_x']**2 + df_seq['acc_y']**2 + df_seq['acc_z']**2)\n            df_seq['rot_angle'] = 2 * np.arccos(df_seq['rot_w'].clip(-1, 1))\n            df_seq['acc_mag_jerk'] = df_seq['acc_mag'].diff().fillna(0)\n            df_seq['rot_angle_vel'] = df_seq['rot_angle'].diff().fillna(0)\n            if all(col in df_seq.columns for col in ['acc_x', 'acc_y', 'acc_z', 'rot_x', 'rot_y', 'rot_z', 'rot_w']):\n                linear_accel = remove_gravity_from_acc(\n                    df_seq[['acc_x', 'acc_y', 'acc_z']], \n                    df_seq[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n                )\n                df_seq[['linear_acc_x', 'linear_acc_y', 'linear_acc_z']] = linear_accel\n            else:\n                df_seq['linear_acc_x'] = df_seq.get('acc_x', 0)\n                df_seq['linear_acc_y'] = df_seq.get('acc_y', 0)\n                df_seq['linear_acc_z'] = df_seq.get('acc_z', 0)\n            df_seq['linear_acc_mag'] = np.sqrt(df_seq['linear_acc_x']**2 + df_seq['linear_acc_y']**2 + df_seq['linear_acc_z']**2)\n            df_seq['linear_acc_mag_jerk'] = df_seq['linear_acc_mag'].diff().fillna(0)\n            if all(col in df_seq.columns for col in ['rot_x', 'rot_y', 'rot_z', 'rot_w']):\n                angular_vel = calculate_angular_velocity_from_quat(df_seq[['rot_x', 'rot_y', 'rot_z', 'rot_w']])\n                df_seq[['angular_vel_x', 'angular_vel_y', 'angular_vel_z']] = angular_vel\n            else:\n                df_seq[['angular_vel_x', 'angular_vel_y', 'angular_vel_z']] = 0\n            if all(col in df_seq.columns for col in ['rot_x', 'rot_y', 'rot_z', 'rot_w']):\n                df_seq['angular_distance'] = calculate_angular_distance(df_seq[['rot_x', 'rot_y', 'rot_z', 'rot_w']])\n            else:\n                df_seq['angular_distance'] = 0\n\n        if self.tof_mode != 0:\n            new_columns = {} \n            for i in range(1, 6):\n                pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]\n                tof_data = df_seq[pixel_cols].replace(-1, np.nan)\n                new_columns.update({\n                    f'tof_{i}_mean': tof_data.mean(axis=1),\n                    f'tof_{i}_std': tof_data.std(axis=1),\n                    f'tof_{i}_min': tof_data.min(axis=1),\n                    f'tof_{i}_max': tof_data.max(axis=1)\n                })\n                if self.tof_mode > 1:\n                    region_size = 64 // self.tof_mode\n                    for r in range(self.tof_mode):\n                        region_data = tof_data.iloc[:, r*region_size : (r+1)*region_size]\n                        new_columns.update({\n                            f'tof{self.tof_mode}_{i}_region_{r}_mean': region_data.mean(axis=1),\n                            f'tof{self.tof_mode}_{i}_region_{r}_std': region_data.std(axis=1),\n                            f'tof{self.tof_mode}_{i}_region_{r}_min': region_data.min(axis=1),\n                            f'tof{self.tof_mode}_{i}_region_{r}_max': region_data.max(axis=1)\n                        })\n                if self.tof_mode == -1:\n                    for mode in [2, 4, 8, 16, 32]:\n                        region_size = 64 // mode\n                        for r in range(mode):\n                            region_data = tof_data.iloc[:, r*region_size : (r+1)*region_size]\n                            new_columns.update({\n                                f'tof{mode}_{i}_region_{r}_mean': region_data.mean(axis=1),\n                                f'tof{mode}_{i}_region_{r}_std': region_data.std(axis=1),\n                                f'tof{mode}_{i}_region_{r}_min': region_data.min(axis=1),\n                                f'tof{mode}_{i}_region_{r}_max': region_data.max(axis=1)\n                            })\n            df_seq = pd.concat([df_seq, pd.DataFrame(new_columns)], axis=1)\n        \n        imu_unscaled = df_seq[self.imu_cols]\n        if self.config[\"fbfill\"][\"imu\"]:\n            imu_unscaled = imu_unscaled.ffill().bfill()\n        imu_unscaled = imu_unscaled.fillna(self.imu_nan_value).values.astype('float32')\n\n        thm_unscaled = df_seq[self.thm_cols]\n        if self.config[\"fbfill\"][\"thm\"]:\n            thm_unscaled = thm_unscaled.ffill().bfill()\n        thm_unscaled = thm_unscaled.fillna(self.thm_nan_value).values.astype('float32')\n\n        tof_unscaled = df_seq[self.tof_cols]\n        if self.config[\"fbfill\"][\"tof\"]:\n            tof_unscaled = tof_unscaled.ffill().bfill()\n        tof_unscaled = tof_unscaled.fillna(self.tof_nan_value).values.astype('float32')\n        \n        if self.config.get(\"one_scale\", True):\n            x_unscaled = np.concatenate([imu_unscaled, thm_unscaled, tof_unscaled], axis=1)\n            x_scaled = self.x_scaler.transform(x_unscaled)\n            imu_scaled = x_scaled[..., :self.imu_dim]\n            thm_scaled = x_scaled[..., self.imu_dim:self.imu_dim+self.thm_dim]\n            tof_scaled = x_scaled[..., self.imu_dim+self.thm_dim:self.imu_dim+self.thm_dim+self.tof_dim]\n        else:\n            imu_scaled = self.imu_scaler.transform(imu_unscaled)\n            thm_scaled = self.thm_scaler.transform(thm_unscaled)\n            tof_scaled = self.tof_scaler.transform(tof_unscaled)\n\n        combined = np.concatenate([imu_scaled, thm_scaled, tof_scaled], axis=1)\n        padded = np.zeros((self.pad_len, combined.shape[1]), dtype='float32')\n        seq_len = min(combined.shape[0], self.pad_len)\n        padded[:seq_len] = combined[:seq_len]\n        imu = padded[..., :self.imu_dim]\n        thm = padded[..., self.imu_dim:self.imu_dim+self.thm_dim]\n        tof = padded[..., self.imu_dim+self.thm_dim:self.imu_dim+self.thm_dim+self.tof_dim]\n        \n        return torch.from_numpy(imu).float().unsqueeze(0), torch.from_numpy(thm).float().unsqueeze(0), torch.from_numpy(tof).float().unsqueeze(0)\n\n    def __getitem__(self, idx):\n        return self.imu[idx], self.thm[idx], self.tof[idx], self.class_[idx]\n\n    def __len__(self):\n        return len(self.class_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T11:06:56.825802Z","iopub.execute_input":"2025-09-01T11:06:56.826511Z","iopub.status.idle":"2025-09-01T11:06:56.871750Z","shell.execute_reply.started":"2025-09-01T11:06:56.826487Z","shell.execute_reply":"2025-09-01T11:06:56.871213Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"---\n\nThis class is a **cross-validation wrapper** around a full dataset (`CMIFeDataset`).\n\n### What it does:\n\n1. **Initializes**:\n\n   * Builds the full dataset using `full_dataset_function` (e.g., `CMIFeDataset`).\n   * Stores feature dimensions (IMU, thermal, ToF), label encoder, class names, and class weights.\n   * Creates a **StratifiedKFold** object for *n*-fold cross-validation (preserving class balance in each split).\n   * Generates all fold train/validation index splits in advance.\n\n2. **Provides**:\n\n   * `get_fold_datasets(fold_idx)` → returns PyTorch `Subset` objects for training and validation for a given fold.\n   * `print_fold_stats()` → prints how many samples per class are in train/valid sets for each fold (helps verify balanced splits).\n\n---\n\n✅ **Purpose**: Makes it easy to run stratified *n*-fold cross-validation on a dataset while keeping all feature preprocessing identical.\n✅ **Key benefit**: Automatically handles train/validation splitting with label balance and quick class distribution inspection.\n\n---\n","metadata":{}},{"cell_type":"code","source":"# CMIFoldDataset for StratifiedKFold\nclass CMIFoldDataset:\n    def __init__(self, data_path, config, full_dataset_function, n_folds=5, random_seed=42):\n        self.full_dataset = full_dataset_function(data_path=data_path, config=config)\n        self.imu_dim = self.full_dataset.imu_dim\n        self.thm_dim = self.full_dataset.thm_dim\n        self.tof_dim = self.full_dataset.tof_dim\n        self.le = self.full_dataset.le\n        self.class_names = self.full_dataset.le.classes_\n        self.class_weight = self.full_dataset.class_weight\n        self.n_folds = n_folds\n        self.skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_seed)\n        self.folds = list(self.skf.split(np.arange(len(self.full_dataset)), np.array(self.full_dataset.dataset_indices)))\n    \n    def get_fold_datasets(self, fold_idx):\n        if self.folds is None or fold_idx >= self.n_folds:\n            return None, None\n        fold_train_idx, fold_valid_idx = self.folds[fold_idx]\n        return Subset(self.full_dataset, fold_train_idx), Subset(self.full_dataset, fold_valid_idx)\n\n    def print_fold_stats(self):\n        def get_label_counts(subset):\n            counts = {name: 0 for name in self.class_names}\n            if subset is None:\n                return counts\n            for idx in subset.indices:\n                label_idx = self.full_dataset.dataset_indices[idx]\n                counts[self.class_names[label_idx]] += 1\n            return counts\n        \n        print(\"\\nCross-validation fold statistics:\")\n        for fold_idx in range(self.n_folds):\n            train_fold, valid_fold = self.get_fold_datasets(fold_idx)\n            train_counts = get_label_counts(train_fold)\n            valid_counts = get_label_counts(valid_fold)\n                \n            print(f\"\\nFold {fold_idx + 1}:\")\n            print(f\"{'name':<50} {'train_counts':<10} {'valid_counts':<10}\")\n            for name in self.class_names:\n                print(f\"{name:<50} {train_counts[name]:<10} {valid_counts[name]:<10}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T11:07:03.429341Z","iopub.execute_input":"2025-09-01T11:07:03.430053Z","iopub.status.idle":"2025-09-01T11:07:03.442053Z","shell.execute_reply.started":"2025-09-01T11:07:03.430019Z","shell.execute_reply":"2025-09-01T11:07:03.440784Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"Here’s the side-by-side diagram showing how **`CMIFeDataset`** and **`CMIFoldDataset`** relate:\n\n---\n\n**Flow Diagram — Full Pipeline**\n\n```\n                ┌──────────────────────────────────┐\n                │  CMIFeDataset                     │\n                │----------------------------------│\n                │  1. Load CSV (raw sensor data)    │\n                │  2. Init feature names            │\n                │  3. Feature engineering           │\n                │     - IMU engineered features     │\n                │     - ToF aggregated stats        │\n                │  4. Handle missing data           │\n                │  5. Scale & pad sequences         │\n                │  6. Encode labels + weights       │\n                │  7. Store tensors (imu/thm/tof)   │\n                └──────────────────────────────────┘\n                              │\n                              ▼\n        (Full processed dataset: ready for model training)\n                              │\n                              ▼\n                ┌──────────────────────────────────┐\n                │  CMIFoldDataset                   │\n                │----------------------------------│\n                │  1. Takes CMIFeDataset as input   │\n                │  2. Uses StratifiedKFold to split │\n                │     into n folds (balanced)       │\n                │  3. Stores train/valid indices    │\n                │  4. get_fold_datasets(fold_idx)   │\n                │     → Returns PyTorch Subsets     │\n                │  5. print_fold_stats() shows      │\n                │     per-class sample counts       │\n                └──────────────────────────────────┘\n```\n\n**Relationship**:\n\n* **`CMIFeDataset`** = **full data preparation engine** (raw CSV → clean, scaled, padded tensors).\n* **`CMIFoldDataset`** = **cross-validation manager** (splits the already-prepared dataset into balanced folds).\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"# **Model Construction**","metadata":{}},{"cell_type":"markdown","source":"**Classes**","metadata":{}},{"cell_type":"markdown","source":"This `SEBlock` is a **Squeeze-and-Excitation** module for 1D features.\n\n**Short explanation:**\nIt learns **channel-wise attention weights** to emphasize important feature channels and suppress less useful ones.\n\n**Steps:**\n\n1. **Squeeze:** `adaptive_avg_pool1d` reduces each channel to a single value → global average per channel.\n2. **Excitation:** Two small fully connected layers (with reduction ratio) learn how important each channel is.\n3. **Scale:** A `sigmoid` gives weights in `[0, 1]` for each channel, which are multiplied back with the original `x`.\n\nEffect: Channels that help the task get boosted, and noisy channels get weakened.\n","metadata":{}},{"cell_type":"code","source":"class SEBlock(nn.Module):\n    def __init__(self, channels, reduction = 8):\n        super().__init__()\n        self.fc1 = nn.Linear(channels, channels // reduction, bias=True)\n        self.fc2 = nn.Linear(channels // reduction, channels, bias=True)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        # x: (B, C, L)\n        se = F.adaptive_avg_pool1d(x, 1).squeeze(-1)      # -> (B, C)\n        se = F.relu(self.fc1(se), inplace=True)          # -> (B, C//r)\n        se = self.sigmoid(self.fc2(se)).unsqueeze(-1)    # -> (B, C, 1)\n        return x * se                ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T11:07:06.984094Z","iopub.execute_input":"2025-09-01T11:07:06.985078Z","iopub.status.idle":"2025-09-01T11:07:06.990307Z","shell.execute_reply.started":"2025-09-01T11:07:06.984967Z","shell.execute_reply":"2025-09-01T11:07:06.989576Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"This `ResNetSEBlock` is basically a **1D ResNet block with a Squeeze-and-Excitation (SE) module**.\n\n**Short explanation:**\nIt applies two convolution layers with batch normalization and ReLU, recalibrates channel importance using **SEBlock**, adds a residual (shortcut) connection, and applies ReLU again.\n\n**Steps:**\n\n1. **Main path:**\n\n   * Conv1D → BN → ReLU\n   * Conv1D → BN\n   * SEBlock to apply channel attention.\n2. **Shortcut path:**\n\n   * If input/output channels differ → 1×1 Conv + BN to match dimensions.\n   * Else, pass identity directly.\n3. **Add & Activate:**\n\n   * Sum main path output and shortcut.\n   * Apply final ReLU.\n\n**Effect:**\nKeeps the benefits of residual learning (easy gradient flow, deeper networks) while also letting the network focus on **important channels** via the SE module.\n","metadata":{}},{"cell_type":"code","source":"class ResNetSEBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, wd = 1e-4):\n        super().__init__()\n        self.conv1 = nn.Conv1d(in_channels, out_channels,\n                               kernel_size=3, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm1d(out_channels)\n        self.conv2 = nn.Conv1d(out_channels, out_channels,\n                               kernel_size=3, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm1d(out_channels)\n        # SE\n        self.se = SEBlock(out_channels)\n        \n        if in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv1d(in_channels, out_channels, kernel_size=1,\n                          padding=0, bias=False),\n                nn.BatchNorm1d(out_channels)\n            )\n        else:\n            self.shortcut = nn.Identity()\n\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x) :\n        identity = self.shortcut(x)              # (B, out, L)\n        out = self.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out = self.se(out)                       # (B, out, L)\n        out = out + identity\n        return self.relu(out)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T11:07:09.686114Z","iopub.execute_input":"2025-09-01T11:07:09.686394Z","iopub.status.idle":"2025-09-01T11:07:09.692981Z","shell.execute_reply.started":"2025-09-01T11:07:09.686372Z","shell.execute_reply":"2025-09-01T11:07:09.692117Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"This `CMIModel` is a **multi-branch deep learning model** that processes **three different sensor inputs** (IMU, thermal (thm), and time-of-flight (tof)) separately, fuses them, and uses a **BERT-based transformer** for sequence modeling before classification.\n\n---\n\n### **Short explanation**\n\n1. **Three feature extraction branches:**\n\n   * **IMU branch** → uses multiple `ResNetSEBlock`s for deep feature extraction with channel attention (SE).\n   * **THM branch** → two Conv1D + BN + ReLU + MaxPool layers.\n   * **TOF branch** → similar to THM branch.\n\n2. **Fusion:**\n\n   * After extracting features, concatenates them along the **feature dimension**.\n\n3. **BERT for sequence modeling:**\n\n   * Adds a trainable `cls_token` (like in Vision Transformers).\n   * Passes the sequence through a BERT encoder (custom config).\n   * Uses the output of the `cls_token` position as the **global representation**.\n\n4. **Classification:**\n\n   * A multi-layer fully connected classifier converts the BERT output into final class scores.\n\n---\n\n### **Data flow (forward pass)**\n\n1. **IMU input** `(B, L, imu_dim)` → `permute` to `(B, imu_dim, L)` → goes through **IMU branch** (ResNetSE + pooling + dropout) → `(B, feat_dim, reduced_L)`.\n2. **THM input** `(B, L, thm_dim)` → similar but with Conv1D layers → `(B, feat_dim, reduced_L)`.\n3. **TOF input** `(B, L, tof_dim)` → similar Conv1D layers → `(B, feat_dim, reduced_L)`.\n4. **Concat features** → `(B, reduced_L, feat_dim_total)` → transformer input format.\n5. **Add `cls_token`** and feed into **BERT** → `(B, reduced_L+1, feat_dim)`.\n6. **Take `cls_token` output** → classifier → final `(B, n_classes)` logits.\n\n---\n\n**Effect:**\nThis model combines **CNNs for local feature extraction**, **SE blocks for channel attention**, and **BERT for long-range temporal dependencies**, making it suitable for **multi-sensor sequence classification**.\n\n---","metadata":{}},{"cell_type":"code","source":"# CMIModel Class\nclass CMIModel(nn.Module):\n    def __init__(self, imu_dim, thm_dim, tof_dim, n_classes, **kwargs):\n        super().__init__()\n        self.imu_branch = nn.Sequential(\n            self.residual_se_cnn_block(imu_dim, kwargs[\"imu1_channels\"], kwargs[\"imu1_layers\"],\n                                       drop=kwargs[\"imu1_dropout\"]),\n            self.residual_se_cnn_block(kwargs[\"imu1_channels\"], kwargs[\"feat_dim\"], kwargs[\"imu2_layers\"],\n                                       drop=kwargs[\"imu2_dropout\"])\n        )\n\n        self.thm_branch = nn.Sequential(\n            nn.Conv1d(thm_dim, kwargs[\"thm1_channels\"], kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm1d(kwargs[\"thm1_channels\"]),\n            nn.ReLU(inplace=True),\n            nn.MaxPool1d(2, ceil_mode=True),\n            nn.Dropout(kwargs[\"thm1_dropout\"]),\n            \n            nn.Conv1d(kwargs[\"thm1_channels\"], kwargs[\"feat_dim\"], kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm1d(kwargs[\"feat_dim\"]),\n            nn.ReLU(inplace=True),\n            nn.MaxPool1d(2, ceil_mode=True),\n            nn.Dropout(kwargs[\"thm2_dropout\"])\n        )\n        \n        self.tof_branch = nn.Sequential(\n            nn.Conv1d(tof_dim, kwargs[\"tof1_channels\"], kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm1d(kwargs[\"tof1_channels\"]),\n            nn.ReLU(inplace=True),\n            nn.MaxPool1d(2, ceil_mode=True),\n            nn.Dropout(kwargs[\"tof1_dropout\"]),\n            \n            nn.Conv1d(kwargs[\"tof1_channels\"], kwargs[\"feat_dim\"], kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm1d(kwargs[\"feat_dim\"]),\n            nn.ReLU(inplace=True),\n            nn.MaxPool1d(2, ceil_mode=True),\n            nn.Dropout(kwargs[\"tof2_dropout\"])\n        )\n\n        self.cls_token = nn.Parameter(torch.zeros(1, 1, kwargs[\"feat_dim\"]))\n        self.bert = BertModel(BertConfig(\n            hidden_size=kwargs[\"feat_dim\"],\n            num_hidden_layers=kwargs[\"bert_layers\"],\n            num_attention_heads=kwargs[\"bert_heads\"],\n            intermediate_size=kwargs[\"feat_dim\"]*4\n        ))\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(kwargs[\"feat_dim\"], kwargs[\"cls1_channels\"], bias=False),\n            nn.BatchNorm1d(kwargs[\"cls1_channels\"]),\n            nn.ReLU(inplace=True),\n            nn.Dropout(kwargs[\"cls1_dropout\"]),\n            nn.Linear(kwargs[\"cls1_channels\"], kwargs[\"cls2_channels\"], bias=False),\n            nn.BatchNorm1d(kwargs[\"cls2_channels\"]),\n            nn.ReLU(inplace=True),\n            nn.Dropout(kwargs[\"cls2_dropout\"]),\n            nn.Linear(kwargs[\"cls2_channels\"], n_classes)\n        )\n    \n    def residual_se_cnn_block(self, in_channels, out_channels, num_layers, pool_size=2, drop=0.3, wd=1e-4):\n        return nn.Sequential(\n            *[ResNetSEBlock(in_channels=in_channels, out_channels=in_channels) for i in range(num_layers)],\n            ResNetSEBlock(in_channels, out_channels, wd=wd),\n            nn.MaxPool1d(pool_size),\n            nn.Dropout(drop)\n        )\n    \n    def forward(self, imu, thm, tof):\n        imu_feat = self.imu_branch(imu.permute(0, 2, 1))\n        thm_feat = self.thm_branch(thm.permute(0, 2, 1))\n        tof_feat = self.tof_branch(tof.permute(0, 2, 1))\n        \n        bert_input = torch.cat([imu_feat, thm_feat, tof_feat], dim=-1).permute(0, 2, 1)\n        cls_token = self.cls_token.expand(bert_input.size(0), -1, -1)  # (B,1,H)\n        bert_input = torch.cat([cls_token, bert_input], dim=1)  # (B,T+1,H)\n        outputs = self.bert(inputs_embeds=bert_input)\n        pred_cls = outputs.last_hidden_state[:, 0, :]\n\n        return self.classifier(pred_cls)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T11:07:11.948450Z","iopub.execute_input":"2025-09-01T11:07:11.949338Z","iopub.status.idle":"2025-09-01T11:07:11.964352Z","shell.execute_reply.started":"2025-09-01T11:07:11.949302Z","shell.execute_reply":"2025-09-01T11:07:11.963528Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"# **Calling Dataset Creation**","metadata":{}},{"cell_type":"code","source":"CUDA0 = \"cuda:0\"\nseed = 42\nbatch_size = 64\nnum_workers = 4\nn_folds = 5\n\n# universe_csv_path = Path(\"/kaggle/input/cmi-precompute/pytorch/all/1/tof-1_raw.csv\")\n# universe_csv_path = Path(\"/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv\")\nuniverse_csv_path = Path(\"/kaggle/working/train_universe.csv\")\n\ndeterministic = kagglehub.package_import('wasupandceacar/deterministic').deterministic\ndeterministic.init_all(seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T11:07:15.339237Z","iopub.execute_input":"2025-09-01T11:07:15.339554Z","iopub.status.idle":"2025-09-01T11:07:15.522720Z","shell.execute_reply.started":"2025-09-01T11:07:15.339507Z","shell.execute_reply":"2025-09-01T11:07:15.522010Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"**init_dataset() ties them together**\n\nWhen you run:\n```\n    dataset = CMIFoldDataset(..., full_dataset_function=CMIFeDataset)\n```\n\nthe sequence is:\n\n\n1. CMIFoldDataset calls CMIFeDataset(data_path, config)→ Loads and preprocesses the entire dataset once.\n2. Splits that processed dataset into n_folds (cross-validation).\n3. Prints fold stats.\n4. Returns the fold-managed dataset object.\n","metadata":{}},{"cell_type":"markdown","source":"```\n\n CSV file (raw)\n   │\n   ▼\n CMIFeDataset (load + clean + scale + process)\n   │ processed full dataset\n   ▼\n CMIFoldDataset (split into n_folds for CV)\n   │\n   ├── fold 0: train / val\n   ├── fold 1: train / val\n   ├── ...\n   └── fold n: train / val\n\n```\n","metadata":{}},{"cell_type":"code","source":"def init_dataset():\n    dataset_config = {\n        \"percent\": 95,\n        \"scaler_function\": StandardScaler(),\n        \"nan_ratio\": {\n            \"imu\": 0,\n            \"thm\": 0,\n            \"tof\": 0,\n        },\n        \"fbfill\": {\n            \"imu\": True,\n            \"thm\": True,\n            \"tof\": True,\n        },\n        \"one_scale\": True,\n        \"tof_raw\": True,\n        \"tof_mode\": 16,\n        \"save_precompute\": False,\n    }\n    dataset = CMIFoldDataset(universe_csv_path, dataset_config,\n                             n_folds=n_folds, random_seed=seed, full_dataset_function=CMIFeDataset)\n    dataset.print_fold_stats()\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T11:07:17.879505Z","iopub.execute_input":"2025-09-01T11:07:17.880034Z","iopub.status.idle":"2025-09-01T11:07:17.884747Z","shell.execute_reply.started":"2025-09-01T11:07:17.880008Z","shell.execute_reply":"2025-09-01T11:07:17.883986Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"**get_fold_dataset :**\n\n* Calls dataset.get_fold_datasets(fold) → returns (train_dataset, valid_dataset) for that fold.\n* Ignores training dataset (_) and keeps only the validation dataset.\n* Wraps it in a PyTorch DataLoader for batching and parallel loading:\n\n**batch_size = how many samples per batch.\nnum_workers = parallel threads for loading data.\nshuffle=False → validation order is fixed.**\n\n\n* Returns this valid_loader.\n\n","metadata":{}},{"cell_type":"code","source":"def get_fold_dataset(dataset, fold):\n    _, valid_dataset = dataset.get_fold_datasets(fold)\n    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n    return valid_loader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T11:07:20.661054Z","iopub.execute_input":"2025-09-01T11:07:20.661287Z","iopub.status.idle":"2025-09-01T11:07:20.665165Z","shell.execute_reply.started":"2025-09-01T11:07:20.661271Z","shell.execute_reply":"2025-09-01T11:07:20.664305Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"dataset = init_dataset()\n\nmodel_function = CMIModel\nmodel_args = {\"feat_dim\": 500,\n              \"imu1_channels\": 219, \"imu1_dropout\": 0.2946731587132302, \"imu2_dropout\": 0.2697745571929592,\n              \"imu1_weight_decay\": 0.0014824054650601245, \"imu2_weight_decay\": 0.002742543773142381,\n              \"imu1_layers\": 0, \"imu2_layers\": 0,\n              \"thm1_channels\": 82, \"thm1_dropout\": 0.2641274454844702, \"thm2_dropout\": 0.302896343020985, \n              \"tof1_channels\": 82, \"tof1_dropout\": 0.2641274454844702, \"tof2_dropout\": 0.3028963430209852, \n              \"bert_layers\": 8, \"bert_heads\": 10,\n              \"cls1_channels\": 937, \"cls2_channels\": 303, \"cls1_dropout\": 0.2281834512400508, \"cls2_dropout\": 0.22502521934558461}\nmodel_args.update({\n    \"imu_dim\": dataset.full_dataset.imu_dim, \n    \"thm_dim\": dataset.full_dataset.thm_dim,\n    \"tof_dim\": dataset.full_dataset.tof_dim,\n    \"n_classes\": dataset.full_dataset.class_num})\n# model_dir = Path(\"/kaggle/input/cmi-models-public/pytorch/train_fold_model05_tof16_raw/1\")\nmodel_dir = Path(\"/kaggle/input/cmi-model-3-utilities\")\n\nmodel_dicts = [\n    {\n        \"model_function\": model_function,\n        \"model_args\": model_args,\n        # \"model_path\": model_dir / f\"fold{fold}/best_ema.pt\",\n        # \"model_path\": f\"/kaggle/working/models/Bert_Model_CMI_{fold}.pkl\",\n        \"model_path\": model_dir / f\"best_fold{fold}.pt\",\n    } for fold in range(n_folds)\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T11:07:23.889462Z","iopub.execute_input":"2025-09-01T11:07:23.889699Z","iopub.status.idle":"2025-09-01T11:08:41.465067Z","shell.execute_reply.started":"2025-09-01T11:07:23.889683Z","shell.execute_reply":"2025-09-01T11:08:41.464311Z"}},"outputs":[{"name":"stdout","text":"Have precomputed, skip compute.\n\nCross-validation fold statistics:\n\nFold 1:\nname                                               train_counts valid_counts\nAbove ear - pull hair                              511        127       \nCheek - pinch skin                                 509        128       \nDrink from bottle/cup                              129        32        \nEyebrow - pull hair                                510        128       \nEyelash - pull hair                                512        128       \nFeel around in tray and pull out an object         129        32        \nForehead - pull hairline                           512        128       \nForehead - scratch                                 512        128       \nGlasses on/off                                     128        33        \nNeck - pinch skin                                  512        128       \nNeck - scratch                                     512        128       \nPinch knee/leg skin                                129        32        \nPull air toward your face                          381        96        \nScratch knee/leg skin                              129        32        \nText on phone                                      512        128       \nWave hello                                         382        96        \nWrite name in air                                  382        95        \nWrite name on leg                                  129        32        \n\nFold 2:\nname                                               train_counts valid_counts\nAbove ear - pull hair                              511        127       \nCheek - pinch skin                                 509        128       \nDrink from bottle/cup                              129        32        \nEyebrow - pull hair                                510        128       \nEyelash - pull hair                                512        128       \nFeel around in tray and pull out an object         129        32        \nForehead - pull hairline                           512        128       \nForehead - scratch                                 512        128       \nGlasses on/off                                     129        32        \nNeck - pinch skin                                  512        128       \nNeck - scratch                                     512        128       \nPinch knee/leg skin                                129        32        \nPull air toward your face                          381        96        \nScratch knee/leg skin                              129        32        \nText on phone                                      512        128       \nWave hello                                         382        96        \nWrite name in air                                  382        95        \nWrite name on leg                                  129        32        \n\nFold 3:\nname                                               train_counts valid_counts\nAbove ear - pull hair                              510        128       \nCheek - pinch skin                                 510        127       \nDrink from bottle/cup                              129        32        \nEyebrow - pull hair                                511        127       \nEyelash - pull hair                                512        128       \nFeel around in tray and pull out an object         129        32        \nForehead - pull hairline                           512        128       \nForehead - scratch                                 512        128       \nGlasses on/off                                     129        32        \nNeck - pinch skin                                  512        128       \nNeck - scratch                                     512        128       \nPinch knee/leg skin                                128        33        \nPull air toward your face                          382        95        \nScratch knee/leg skin                              129        32        \nText on phone                                      512        128       \nWave hello                                         382        96        \nWrite name in air                                  382        95        \nWrite name on leg                                  128        33        \n\nFold 4:\nname                                               train_counts valid_counts\nAbove ear - pull hair                              510        128       \nCheek - pinch skin                                 510        127       \nDrink from bottle/cup                              129        32        \nEyebrow - pull hair                                511        127       \nEyelash - pull hair                                512        128       \nFeel around in tray and pull out an object         128        33        \nForehead - pull hairline                           512        128       \nForehead - scratch                                 512        128       \nGlasses on/off                                     129        32        \nNeck - pinch skin                                  512        128       \nNeck - scratch                                     512        128       \nPinch knee/leg skin                                129        32        \nPull air toward your face                          382        95        \nScratch knee/leg skin                              128        33        \nText on phone                                      512        128       \nWave hello                                         383        95        \nWrite name in air                                  381        96        \nWrite name on leg                                  129        32        \n\nFold 5:\nname                                               train_counts valid_counts\nAbove ear - pull hair                              510        128       \nCheek - pinch skin                                 510        127       \nDrink from bottle/cup                              128        33        \nEyebrow - pull hair                                510        128       \nEyelash - pull hair                                512        128       \nFeel around in tray and pull out an object         129        32        \nForehead - pull hairline                           512        128       \nForehead - scratch                                 512        128       \nGlasses on/off                                     129        32        \nNeck - pinch skin                                  512        128       \nNeck - scratch                                     512        128       \nPinch knee/leg skin                                129        32        \nPull air toward your face                          382        95        \nScratch knee/leg skin                              129        32        \nText on phone                                      512        128       \nWave hello                                         383        95        \nWrite name in air                                  381        96        \nWrite name on leg                                  129        32        \n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n  warnings.warn(\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"# **Model Training**","metadata":{}},{"cell_type":"code","source":"# dataset.get_fold_datasets(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T11:02:25.651432Z","iopub.execute_input":"2025-09-01T11:02:25.651610Z","iopub.status.idle":"2025-09-01T11:02:25.655005Z","shell.execute_reply.started":"2025-09-01T11:02:25.651595Z","shell.execute_reply":"2025-09-01T11:02:25.654457Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"TARGET_GESTURE_NAMES = list(universe_df['gesture'].astype(str))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T11:08:41.466279Z","iopub.execute_input":"2025-09-01T11:08:41.466495Z","iopub.status.idle":"2025-09-01T11:08:41.507772Z","shell.execute_reply.started":"2025-09-01T11:08:41.466478Z","shell.execute_reply":"2025-09-01T11:08:41.507203Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"def set_seed(seed: int):\n    \"\"\"Make experiments reproducible (best-effort).\"\"\"\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    # Torch deterministic settings (may slow training)\n    try:\n        # Newer PyTorch: prefer strict deterministic algorithms\n        torch.use_deterministic_algorithms(True)\n    except Exception:\n        try:\n            torch.set_deterministic(True)\n        except Exception:\n            pass\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T11:08:41.508438Z","iopub.execute_input":"2025-09-01T11:08:41.508661Z","iopub.status.idle":"2025-09-01T11:08:41.516861Z","shell.execute_reply.started":"2025-09-01T11:08:41.508645Z","shell.execute_reply":"2025-09-01T11:08:41.516251Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"import random \n\ndataset_obj = dataset\nmodel_fn = model_function\nmodel_args = model_args\n\n# Provide target_gesture_names if not auto-detectable from dataset.\n# Replace with actual target gesture names from contest if needed (strings) OR integer ids.\nTARGET_GESTURE_NAMES = globals().get(\"TARGET_GESTURE_NAMES\", None)   # <-- set manually if needed\n\n# Training hyperparams - change if needed\nbatch_size = globals().get(\"batch_size\", 64)\nnum_workers = globals().get(\"num_workers\", 4)\nn_folds = globals().get(\"n_folds\", 5)\nseed = globals().get(\"seed\", 0)\nepochs = 32\nlr = 5e-4\nweight_decay = 1e-4\nsave_dir = Path(\"checkpoints\")\nsave_dir.mkdir(exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# ========= utilities & metric functions =========\n# def set_seed(s):\n#     random.seed(s)\n#     np.random.seed(s)\n#     torch.manual_seed(s)\n#     if torch.cuda.is_available():\n#         torch.cuda.manual_seed_all(s)\n\ndef compute_contest_metrics(y_true, y_pred, target_labels):\n    \"\"\"\n    y_true, y_pred: iterables (either ints or strings) same length\n    target_labels: set/list of labels considered 'target' (same representation as labels)\n    returns dict: binary_f1, gesture_macro_f1, contest_score\n    \"\"\"\n    y_true = np.array(y_true, dtype=object)\n    y_pred = np.array(y_pred, dtype=object)\n    target_set = set(target_labels)\n\n    # Binary mapping: 1 if target, else 0\n    y_true_bin = np.isin(y_true, list(target_set)).astype(int)\n    y_pred_bin = np.isin(y_pred, list(target_set)).astype(int)\n\n    # Binary F1 guards\n    if y_true_bin.sum() == 0 and y_pred_bin.sum() == 0:\n        binary_f1 = 1.0\n    elif y_true_bin.sum() == 0 and y_pred_bin.sum() > 0:\n        binary_f1 = 0.0\n    else:\n        binary_f1 = f1_score(y_true_bin, y_pred_bin, average='binary', pos_label=1)\n\n    # Collapse non-target labels into single token\n    NON_TARGET = \"__NON_TARGET__\"\n    def collapse_label(l):\n        return l if l in target_set else NON_TARGET\n\n    y_true_coll = np.array([collapse_label(x) for x in y_true], dtype=object)\n    y_pred_coll = np.array([collapse_label(x) for x in y_pred], dtype=object)\n\n    # gesture macro f1 with guard\n    if len(np.unique(y_true_coll)) == 1 and (y_true_coll == y_pred_coll).all():\n        gesture_macro_f1 = 1.0\n    else:\n        gesture_macro_f1 = f1_score(y_true_coll, y_pred_coll, average='macro')\n\n    contest_score = 0.5 * (binary_f1 + gesture_macro_f1)\n    return {\"binary_f1\": float(binary_f1), \"gesture_macro_f1\": float(gesture_macro_f1), \"contest_score\": float(contest_score)}\n\n# ========= training / validation functions =========\ndef make_loaders(dataset_obj, fold_idx):\n    \"\"\"Expect dataset_obj.get_fold_datasets(fold_idx) -> (train_dataset, valid_dataset)\"\"\"\n    train_ds, valid_ds = dataset_obj.get_fold_datasets(fold_idx)\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n    valid_loader = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n    return train_loader, valid_loader\n\ndef train_one_epoch(model, loader, optimizer, criterion, device, use_amp=False):\n    model.train()\n    total_loss = 0.0\n    preds = []\n    trues = []\n    #scaler = torch.cuda.amp.GradScaler() if use_amp else None\n    scaler = torch.amp.GradScaler(\"cuda\") if use_amp else None\n\n    for batch in tqdm(loader, desc=\"train\", leave=False):\n        # expecting batch -> (imu, thm, tof, y)\n        imu, thm, tof, y = batch\n        imu = imu.to(device)\n        thm = thm.to(device)\n        tof = tof.to(device)\n        y = y.to(device)#.long()\n\n        # Ensure target is class indices (not one-hot)\n        # if y.ndim > 1 and y.size(1) > 1:\n        #     y = y.argmax(dim=1)\n        # y = y.long()\n        #changes comment\n\n        optimizer.zero_grad()\n        if use_amp:\n            with torch.cuda.amp.autocast():\n                logits = model(imu, thm, tof)\n                loss = criterion(logits, y)\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            logits = model(imu, thm, tof)\n            loss = criterion(logits, y)\n            loss.backward()\n            optimizer.step()\n\n        total_loss += loss.item() * imu.size(0)\n        preds.extend(torch.argmax(logits, dim=1).detach().cpu().numpy().tolist())\n        trues.extend(y.detach().cpu().numpy().tolist())\n\n    avg_loss = total_loss / len(loader.dataset)\n    try:\n        # if labels are integers, compute macro F1 on ids\n        train_f1 = f1_score(trues, preds, average='macro')\n    except Exception:\n        train_f1 = 0.0\n    return avg_loss, train_f1\n\ndef validate_and_score(model, loader, criterion, device, target_labels, id2label=None):\n    model.eval()\n    total_loss = 0.0\n    preds = []\n    trues = []\n\n    with torch.no_grad():\n        for batch in tqdm(loader, desc=\"valid\", leave=False):\n            imu, thm, tof, y = batch\n            imu = imu.to(device)\n            thm = thm.to(device)\n            tof = tof.to(device)\n            y = y.to(device)#.long()  changes comment\n\n            logits = model(imu, thm, tof)\n            loss = criterion(logits, y)\n            total_loss += loss.item() * imu.size(0)\n\n            batch_preds = torch.argmax(logits, dim=1).cpu().numpy()\n            batch_trues = y.cpu().argmax(axis=1).numpy()\n\n            if id2label is not None:\n                batch_preds = [id2label[int(p)] for p in batch_preds]\n                batch_trues = [id2label[int(t)] for t in batch_trues]\n            else:\n                batch_preds = [int(p) for p in batch_preds]\n                batch_trues = [int(t) for t in batch_trues]\n\n            preds.extend(batch_preds)\n            trues.extend(batch_trues)\n\n    avg_loss = total_loss / len(loader.dataset)\n    metrics = compute_contest_metrics(trues, preds, target_labels)\n    return avg_loss, metrics\n\n# ========= main training loop =========\ndef train_all_folds(num_folds=n_folds):\n    set_seed(seed)\n    overall_start = time.time()\n\n    # Try to infer id2label and target set from dataset object\n    id2label = None\n    inferred_target_labels = None\n\n    # attempt common attribute locations\n    fd = getattr(dataset_obj, \"full_dataset\", None)\n    if fd is None:\n        fd = dataset_obj\n\n    # id2label mapping?\n    id2label = getattr(fd, \"id2label\", None) or getattr(fd, \"idx2label\", None) or getattr(fd, \"index_to_label\", None)\n\n    # target labels either explicit in dataset or user-supplied\n    if TARGET_GESTURE_NAMES:\n        inferred_target_labels = TARGET_GESTURE_NAMES\n    else:\n        # common metadata names\n        inferred_target_labels = getattr(fd, \"target_labels\", None) or getattr(fd, \"target_gestures\", None) or getattr(fd, \"targets\", None)\n\n    if inferred_target_labels is None:\n        # if id2label exists AND you have a set of names you want as target you could map them.\n        raise RuntimeError(\"TARGET gestures not found. Please set TARGET_GESTURE_NAMES to a list of target gestures (strings), or ensure dataset.full_dataset.target_labels exists.\")\n\n    print(f\"Using device={device}; batch_size={batch_size}; epochs={epochs}; folds={num_folds}\")\n    print(f\"Detected id2label mapping: {bool(id2label)}; detected target set length: {len(inferred_target_labels)}\")\n\n    for fold in range(num_folds):\n        print(f\"\\n=== Fold {fold} training ===\")\n        train_loader, valid_loader = make_loaders(dataset_obj, fold)\n        model = model_fn(**model_args)\n        model = model.to(device)\n\n        # Use class weights if provided by dataset; else plain CE\n        class_weights = None\n        try:\n            weights = getattr(fd, \"class_weight\", None) or getattr(fd, \"class_weights\", None)\n            if weights is not None:\n                class_weights = torch.tensor(weights, dtype=torch.float32).to(device)\n        except Exception:\n            class_weights = None\n\n        criterion = nn.CrossEntropyLoss(weight=class_weights) if class_weights is not None else nn.CrossEntropyLoss()\n        # optimizer\n        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max(1, epochs//2))\n\n        best_metric = -1.0\n        best_epoch = -1\n\n        for epoch in range(1, epochs+1):\n            start = time.time()\n            train_loss, train_f1 = train_one_epoch(model, train_loader, optimizer, criterion, device, use_amp=True)\n            val_loss, val_metrics = validate_and_score(model, valid_loader, criterion, device, inferred_target_labels, id2label=id2label)\n            scheduler.step()\n\n            epoch_time = time.time() - start\n            print(f\"Fold{fold} Epoch {epoch:02d}/{epochs} | time {epoch_time:.1f}s | train_loss {train_loss:.4f} train_macroF1 {train_f1:.4f} | val_loss {val_loss:.4f} | binaryF1 {val_metrics['binary_f1']:.4f} | gestureMacroF1 {val_metrics['gesture_macro_f1']:.4f} | contest {val_metrics['contest_score']:.4f}\")\n\n            # save best by contest score\n            if val_metrics['contest_score'] > best_metric:\n                best_metric = val_metrics['contest_score']\n                best_epoch = epoch\n                ckpt = {\n                    \"epoch\": epoch,\n                    \"model_state_dict\": model.state_dict(),\n                    \"optimizer_state_dict\": optimizer.state_dict(),\n                    \"val_metrics\": val_metrics,\n                    \"model_args\": model_args\n                }\n                # torch.save(ckpt, save_dir / f\"best_fold{fold}.pt\")\n                torch.save(ckpt, f\"best_fold{fold}.pt\")\n                # joblib.dump(ckpt,f\"/kaggle/working/models/Bert_Model_CMI_{fold}.pkl\")\n                # joblib.dump(ckpt,save_dir / f\"Bert_Model_CMI_{fold}.pkl\")\n\n        print(f\"Fold {fold} finished. Best contest score {best_metric:.4f} at epoch {best_epoch}\")\n\n    total_time = time.time() - overall_start\n    print(f\"\\nAll folds done in {total_time/60:.1f} minutes.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T11:08:41.518486Z","iopub.execute_input":"2025-09-01T11:08:41.518737Z","iopub.status.idle":"2025-09-01T11:08:41.688301Z","shell.execute_reply.started":"2025-09-01T11:08:41.518713Z","shell.execute_reply":"2025-09-01T11:08:41.687517Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# ========== run/training ==========\nif __name__ == \"__main__\":\n    train_all_folds()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"models2 = list()\nfor model_dict in model_dicts:\n    model_function = model_dict[\"model_function\"]\n    model_args = model_dict[\"model_args\"]\n    model_path = model_dict[\"model_path\"]\n    model = model_function(**model_args).to(CUDA0)\n    ckpt = torch.load(model_path)\n    state_dict = {k.replace(\"_orig_mod.\", \"\"): v for k, v in ckpt[\"model_state_dict\"].items()}\n    model.load_state_dict(state_dict)\n    model = model.eval()\n    models2.append(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T11:08:41.689152Z","iopub.execute_input":"2025-09-01T11:08:41.689397Z","iopub.status.idle":"2025-09-01T11:08:58.437161Z","shell.execute_reply.started":"2025-09-01T11:08:41.689380Z","shell.execute_reply":"2025-09-01T11:08:58.436590Z"}},"outputs":[],"execution_count":36}]}